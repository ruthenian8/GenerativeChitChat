{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMsFpbzaEGVarSTZOP+f9L"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "OWELiZXsZc04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTkfrU8dUleK",
        "outputId": "38a753cc-a0d0-4827-a30a-cd34fc6a3c38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/qa_data.jsonl.zip ."
      ],
      "metadata": {
        "id": "nho5GlT5U6sD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip qa_data.jsonl.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wUHz064VIXF",
        "outputId": "a52dffa4-33ea-41ee-fbc5-671332a886b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 200000 qa_data.jsonl > train.jsonl\n",
        "!head -n 250000 qa_data.jsonl | tail -n 50000 > valid.jsonl\n",
        "!head -n 300000 qa_data.jsonl | tail -n 50000 > test.jsonl"
      ],
      "metadata": {
        "id": "Pz3sGsVuXRXW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtokentome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIzffXqg5kr_",
        "outputId": "9c675afc-c73f-4108-f08a-ea0cf3ea60ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 500000 qa_data.jsonl | sed 's/[^0-9а-яА-Я \\-\\.\\?]//g' | sed 's/  / /g' > forbpe.txt"
      ],
      "metadata": {
        "id": "gzC1tycl57xu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "1NKkdN9-Zk1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "q9bI-ZU4Kn86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import BucketIterator"
      ],
      "metadata": {
        "id": "JG5iJFKbPV9W"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import youtokentome as yttm"
      ],
      "metadata": {
        "id": "JWv5-XEh5tZq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.nn import MultiHeadAttentionContainer, InProjContainer, ScaledDotProduct"
      ],
      "metadata": {
        "id": "mUuQGrc4x0dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка"
      ],
      "metadata": {
        "id": "zGQFmJ9j-Xfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'\n",
        "yttm.BPE.train(data='forbpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tr6Y-mA-RDg",
        "outputId": "5c04de8b-140d-4f2b-b1da-cebfc055a85f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.8 s, sys: 2.84 s, total: 20.6 s\n",
            "Wall time: 12.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = yttm.BPE(model=model_path)\n",
        "(PAD_TOKEN,\n",
        "UNK_TOKEN,\n",
        "START_TOKEN,\n",
        "END_TOKEN) = tokenizer.vocab()[:4]"
      ],
      "metadata": {
        "id": "p0j-FGpH-l4I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oURLpx5GG1qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, filename, _tokenizer=None, MAX_LEN=64):\n",
        "        super().__init__()\n",
        "        if _tokenizer is None:\n",
        "            _tokenizer = tokenizer\n",
        "        self._tokenizer = _tokenizer\n",
        "        questions = []\n",
        "        responses = []\n",
        "        self.length: int\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "            for line in file:\n",
        "                line = line.strip(\"\\n\").strip(\"\\r\")\n",
        "                line_dict = json.loads(line)\n",
        "                question = line_dict[\"question\"]\n",
        "                response = line_dict[\"responses\"]\n",
        "                if len(response) == 0:\n",
        "                    continue\n",
        "                questions.append(\n",
        "                    self._tokenize(question, MAX_LEN)\n",
        "                )\n",
        "                responses.append(\n",
        "                    self._tokenize(response[0], MAX_LEN)\n",
        "                )\n",
        "            else:\n",
        "                assert len(questions) == len(responses)\n",
        "                self.length = len(questions)\n",
        "        self.questions = torch.nn.utils.rnn.pad_sequence(\n",
        "            questions,\n",
        "            batch_first=True,\n",
        "            padding_value=self._tokenizer.subword_to_id(PAD_TOKEN)\n",
        "        )\n",
        "        self.responses = torch.nn.utils.rnn.pad_sequence(\n",
        "            questions,\n",
        "            batch_first=True,\n",
        "            padding_value=self._tokenizer.subword_to_id(PAD_TOKEN)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return (\n",
        "            self.questions[item],\n",
        "            self.responses[item]\n",
        "        )\n",
        "\n",
        "    def _tokenize(self, text, max_len):\n",
        "        return torch.LongTensor(\n",
        "            self._tokenizer.encode(text, bos=True, eos=True)[:max_len]\n",
        "        )"
      ],
      "metadata": {
        "id": "2Ibs0Kf-1yk7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    train_dataloader,\n",
        "    valid_dataloader,\n",
        "    test_dataloader\n",
        ") = BucketIterator(\n",
        "    (train_dataset, valid_dataset, test_dataset),\n",
        "    batch_sizes=(128, 128, 128),\n",
        "    device=device,\n",
        "    sort_key=lambda x: torch.count_nonzero(x[0]),\n",
        "    sort=True,\n",
        "    shuffle=True,\n",
        "    sort_within_batch=False\n",
        ")"
      ],
      "metadata": {
        "id": "DjzaqFGQG2mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель"
      ],
      "metadata": {
        "id": "u4i3QI5OIlfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFF(nn.Module):\n",
        "    def __init__(self, embed_dim, pf_dim, dropout):\n",
        "        self.hidden = nn.Linear(embed_dim, pf_dim)\n",
        "        self.gate = nn.Linear(pf_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, embedding):\n",
        "        hidden = self.dropout(\n",
        "            torch.relu(self.hidden(embedding))\n",
        "        )\n",
        "        return self.gate(hidden)"
      ],
      "metadata": {
        "id": "I9xcSkc01YtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        num_heads,\n",
        "        pf_dim,\n",
        "        dropout\n",
        "    ):\n",
        "        assert embed_dim % num_heads == 0\n",
        "        super().__init__()\n",
        "        self.norm_attention = nn.LayerNorm(embed_dim)\n",
        "        self.norm_ff = nn.LayerNorm(embed_dim)\n",
        "        projection_container = InProjContainer(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "        self.selfAttention = MultiHeadAttentionContainer(\n",
        "            num_heads,\n",
        "            projection_container,\n",
        "            ScaledDotProduct(dropout=dropout),\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "        self.ff = PositionWiseFF(embed_dim, pf_dim, dropout)\n",
        "\n",
        "    def forward(self, embedding, mask):\n",
        "        mha_out, _ = self.selfAttention(*([embedding] * 3), mask)\n",
        "        normalized = self.normAttention(embedding + mha_out)\n",
        "        gated = self.ff(embedding)\n",
        "        return self.norm_ff(\n",
        "            normalized + gated\n",
        "        )"
      ],
      "metadata": {
        "id": "tXAf2NDrsAvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение"
      ],
      "metadata": {
        "id": "tVmmwgjAIiXb"
      }
    }
  ]
}