{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3nGfqYvE/U1SF076TBUjC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "OWELiZXsZc04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTkfrU8dUleK",
        "outputId": "38a753cc-a0d0-4827-a30a-cd34fc6a3c38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/qa_data.jsonl.zip ."
      ],
      "metadata": {
        "id": "nho5GlT5U6sD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip qa_data.jsonl.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wUHz064VIXF",
        "outputId": "a52dffa4-33ea-41ee-fbc5-671332a886b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  qa_data.jsonl.zip\n",
            "  inflating: qa_data.jsonl           \n",
            "  inflating: __MACOSX/._qa_data.jsonl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 200000 qa_data.jsonl > train.jsonl\n",
        "!head -n 250000 qa_data.jsonl | tail -n 50000 > valid.jsonl\n",
        "!head -n 300000 qa_data.jsonl | tail -n 50000 > test.jsonl"
      ],
      "metadata": {
        "id": "Pz3sGsVuXRXW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtokentome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIzffXqg5kr_",
        "outputId": "9c675afc-c73f-4108-f08a-ea0cf3ea60ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 500000 qa_data.jsonl | sed 's/[^0-9а-яА-Я \\-\\.\\?]//g' | sed 's/  / /g' > forbpe.txt"
      ],
      "metadata": {
        "id": "gzC1tycl57xu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "1NKkdN9-Zk1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "q9bI-ZU4Kn86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import BucketIterator"
      ],
      "metadata": {
        "id": "JG5iJFKbPV9W"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import youtokentome as yttm"
      ],
      "metadata": {
        "id": "JWv5-XEh5tZq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка"
      ],
      "metadata": {
        "id": "zGQFmJ9j-Xfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vocab_size = 30_000\n",
        "model_path = 'pretrained_bpe_lm.model'\n",
        "yttm.BPE.train(data='forbpe.txt', vocab_size=vocab_size, model=model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tr6Y-mA-RDg",
        "outputId": "5c04de8b-140d-4f2b-b1da-cebfc055a85f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.8 s, sys: 2.84 s, total: 20.6 s\n",
            "Wall time: 12.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = yttm.BPE(model=model_path)"
      ],
      "metadata": {
        "id": "p0j-FGpH-l4I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(PAD_TOKEN,\n",
        "UNK_TOKEN,\n",
        "START_TOKEN,\n",
        "END_TOKEN) = tokenizer.vocab()[:4]"
      ],
      "metadata": {
        "id": "Tqq_vx1S2VlF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.subword_to_id(PAD_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M-nXazjEKmK",
        "outputId": "0033456a-c4f7-46d9-a058-81c7f840e1e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, filename, _tokenizer=None, MAX_LEN=64):\n",
        "        super().__init__()\n",
        "        if _tokenizer is None:\n",
        "            _tokenizer = tokenizer\n",
        "        self._tokenizer = _tokenizer\n",
        "        questions = []\n",
        "        responses = []\n",
        "        self.length: int\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "            for line in file:\n",
        "                line = line.strip(\"\\n\").strip(\"\\r\")\n",
        "                line_dict = json.loads(line)\n",
        "                question = line_dict[\"question\"]\n",
        "                response = line_dict[\"responses\"]\n",
        "                if len(response) == 0:\n",
        "                    continue\n",
        "                questions.append(\n",
        "                    self._tokenize(question, MAX_LEN)\n",
        "                )\n",
        "                responses.append(\n",
        "                    self._tokenize(response[0], MAX_LEN)\n",
        "                )\n",
        "            else:\n",
        "                assert len(questions) == len(responses)\n",
        "                self.length = len(questions)\n",
        "        self.questions = torch.nn.utils.rnn.pad_sequence(\n",
        "            questions,\n",
        "            batch_first=True,\n",
        "            padding_value=self._tokenizer.subword_to_id(PAD_TOKEN)\n",
        "        )\n",
        "        self.responses = torch.nn.utils.rnn.pad_sequence(\n",
        "            questions,\n",
        "            batch_first=True,\n",
        "            padding_value=self._tokenizer.subword_to_id(PAD_TOKEN)\n",
        "        )\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.questions[item], self.responses[item]\n",
        "\n",
        "    def _tokenize(self, text, max_len):\n",
        "        return torch.LongTensor(\n",
        "            self._tokenizer.encode(text, bos=True, eos=True)[:max_len]\n",
        "        )"
      ],
      "metadata": {
        "id": "2Ibs0Kf-1yk7"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}